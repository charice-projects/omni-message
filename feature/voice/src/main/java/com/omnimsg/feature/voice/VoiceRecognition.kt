// ğŸ“ feature/voice/VoiceRecognition.kt
package com.omnimsg.feature.voice

import android.content.Context
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import kotlinx.coroutines.CancellationException
import kotlinx.coroutines.channels.awaitClose
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.callbackFlow
import kotlinx.coroutines.suspendCancellableCoroutine
import java.util.Locale
import javax.inject.Inject
import javax.inject.Singleton
import kotlin.coroutines.resume
import kotlin.coroutines.resumeWithException

@Singleton
class VoiceRecognition @Inject constructor(
    private val context: Context
) {
    
    sealed class RecognitionResult {
        data class Success(
            val text: String,
            val confidence: Float,
            val alternatives: List<String> = emptyList()
        ) : RecognitionResult()
        
        data class Partial(
            val text: String
        ) : RecognitionResult()
        
        object NoMatch : RecognitionResult()
        data class Error(
            val errorCode: Int,
            val message: String
        ) : RecognitionResult()
    }
    
    interface VoiceRecognitionListener {
        fun onResult(result: RecognitionResult)
        fun onError(error: String)
        fun onStatusChanged(isListening: Boolean)
    }
    
    private var speechRecognizer: SpeechRecognizer? = null
    private var isListening = false
    private val listeners = mutableListOf<VoiceRecognitionListener>()
    
    /**
     * åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
     */
    fun initialize(): Boolean {
        return try {
            speechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)
            true
        } catch (e: Exception) {
            logger.e("VoiceRecognition", "åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¤±è´¥", e)
            false
        }
    }
    
    /**
     * å¼€å§‹è¯­éŸ³è¯†åˆ«
     */
    suspend fun startRecognition(
        language: String = "zh-CN",
        partialResults: Boolean = true
    ): Flow<RecognitionResult> = callbackFlow {
        if (!initialize()) {
            trySend(RecognitionResult.Error(-1, "è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥"))
            close()
            return@callbackFlow
        }
        
        val recognizer = speechRecognizer ?: return@callbackFlow
        
        // è®¾ç½®è¯†åˆ«ç›‘å¬å™¨
        val recognitionListener = object : RecognitionListener {
            override fun onReadyForSpeech(params: android.os.Bundle) {
                logger.d("VoiceRecognition", "å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è¯´è¯")
                isListening = true
                notifyStatusChanged(true)
            }
            
            override fun onBeginningOfSpeech() {
                logger.d("VoiceRecognition", "æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
            }
            
            override fun onRmsChanged(rmsdB: Float) {
                // éŸ³é‡å˜åŒ–ï¼Œå¯ç”¨äºå¯è§†åŒ–
            }
            
            override fun onBufferReceived(buffer: ByteArray) {
                // éŸ³é¢‘ç¼“å†²åŒºæ¥æ”¶
            }
            
            override fun onEndOfSpeech() {
                logger.d("VoiceRecognition", "è¯­éŸ³ç»“æŸ")
                isListening = false
                notifyStatusChanged(false)
            }
            
            override fun onError(error: Int) {
                isListening = false
                notifyStatusChanged(false)
                
                val errorMessage = when (error) {
                    SpeechRecognizer.ERROR_AUDIO -> "éŸ³é¢‘é”™è¯¯"
                    SpeechRecognizer.ERROR_CLIENT -> "å®¢æˆ·ç«¯é”™è¯¯"
                    SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> "æƒé™ä¸è¶³"
                    SpeechRecognizer.ERROR_NETWORK -> "ç½‘ç»œé”™è¯¯"
                    SpeechRecognizer.ERROR_NETWORK_TIMEOUT -> "ç½‘ç»œè¶…æ—¶"
                    SpeechRecognizer.ERROR_NO_MATCH -> "æ²¡æœ‰åŒ¹é…çš„ç»“æœ"
                    SpeechRecognizer.ERROR_RECOGNIZER_BUSY -> "è¯†åˆ«å™¨å¿™"
                    SpeechRecognizer.ERROR_SERVER -> "æœåŠ¡å™¨é”™è¯¯"
                    SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> "è¯­éŸ³è¶…æ—¶"
                    else -> "æœªçŸ¥é”™è¯¯: $error"
                }
                
                logger.e("VoiceRecognition", "è¯­éŸ³è¯†åˆ«é”™è¯¯: $errorMessage")
                notifyError(errorMessage)
                
                trySend(RecognitionResult.Error(error, errorMessage))
            }
            
            override fun onResults(results: android.os.Bundle) {
                val matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                val confidences = results.getFloatArray(SpeechRecognizer.CONFIDENCE_SCORES)
                
                if (!matches.isNullOrEmpty()) {
                    val bestMatch = matches[0]
                    val confidence = confidences?.getOrNull(0) ?: 0.5f
                    val alternatives = matches.drop(1)
                    
                    logger.d("VoiceRecognition", "è¯†åˆ«ç»“æœ: $bestMatch (ç½®ä¿¡åº¦: $confidence)")
                    
                    val recognitionResult = RecognitionResult.Success(
                        text = bestMatch,
                        confidence = confidence,
                        alternatives = alternatives
                    )
                    
                    trySend(recognitionResult)
                    notifyResult(recognitionResult)
                } else {
                    trySend(RecognitionResult.NoMatch)
                }
            }
            
            override fun onPartialResults(partialResults: android.os.Bundle) {
                if (partialResults) {
                    val matches = partialResults.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    matches?.firstOrNull()?.let { partialText ->
                        logger.d("VoiceRecognition", "éƒ¨åˆ†ç»“æœ: $partialText")
                        trySend(RecognitionResult.Partial(partialText))
                    }
                }
            }
            
            override fun onEvent(eventType: Int, params: android.os.Bundle) {
                // äº‹ä»¶å›è°ƒ
            }
        }
        
        recognizer.setRecognitionListener(recognitionListener)
        
        // è®¾ç½®è¯†åˆ«æ„å›¾
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, language)
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, partialResults)
            putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 5)
            putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS, 3000)
            putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS, 2000)
            putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS, 1500)
        }
        
        // å¼€å§‹è¯†åˆ«
        recognizer.startListening(intent)
        
        awaitClose {
            stopRecognition()
        }
    }
    
    /**
     * åœæ­¢è¯­éŸ³è¯†åˆ«
     */
    fun stopRecognition() {
        speechRecognizer?.stopListening()
        speechRecognizer?.cancel()
        isListening = false
        notifyStatusChanged(false)
    }
    
    /**
     * å•æ¬¡è¯­éŸ³è¯†åˆ«
     */
    suspend fun recognizeOneShot(
        language: String = "zh-CN",
        timeoutMillis: Long = 10000
    ): RecognitionResult {
        return suspendCancellableCoroutine { continuation ->
            if (!initialize()) {
                continuation.resume(RecognitionResult.Error(-1, "è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥"))
                return@suspendCancellableCoroutine
            }
            
            val recognizer = speechRecognizer!!
            var timeoutJob: Job? = null
            
            val recognitionListener = object : RecognitionListener {
                override fun onReadyForSpeech(params: android.os.Bundle) {
                    logger.d("VoiceRecognition", "å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è¯´è¯")
                    isListening = true
                    
                    // è®¾ç½®è¶…æ—¶
                    timeoutJob = CoroutineScope(Dispatchers.IO).launch {
                        delay(timeoutMillis)
                        if (isListening) {
                            onError(SpeechRecognizer.ERROR_SPEECH_TIMEOUT)
                        }
                    }
                }
                
                override fun onBeginningOfSpeech() {
                    logger.d("VoiceRecognition", "æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
                }
                
                override fun onEndOfSpeech() {
                    logger.d("VoiceRecognition", "è¯­éŸ³ç»“æŸ")
                    isListening = false
                    timeoutJob?.cancel()
                }
                
                override fun onError(error: Int) {
                    isListening = false
                    timeoutJob?.cancel()
                    
                    val errorMessage = when (error) {
                        SpeechRecognizer.ERROR_AUDIO -> "éŸ³é¢‘é”™è¯¯"
                        SpeechRecognizer.ERROR_CLIENT -> "å®¢æˆ·ç«¯é”™è¯¯"
                        SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> "æƒé™ä¸è¶³"
                        SpeechRecognizer.ERROR_NETWORK -> "ç½‘ç»œé”™è¯¯"
                        SpeechRecognizer.ERROR_NETWORK_TIMEOUT -> "ç½‘ç»œè¶…æ—¶"
                        SpeechRecognizer.ERROR_NO_MATCH -> "æ²¡æœ‰åŒ¹é…çš„ç»“æœ"
                        SpeechRecognizer.ERROR_RECOGNIZER_BUSY -> "è¯†åˆ«å™¨å¿™"
                        SpeechRecognizer.ERROR_SERVER -> "æœåŠ¡å™¨é”™è¯¯"
                        SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> "è¯´è¯è¶…æ—¶"
                        else -> "æœªçŸ¥é”™è¯¯: $error"
                    }
                    
                    logger.e("VoiceRecognition", "å•æ¬¡è¯†åˆ«é”™è¯¯: $errorMessage")
                    
                    if (!continuation.isCancelled) {
                        continuation.resume(RecognitionResult.Error(error, errorMessage))
                    }
                    
                    cleanup()
                }
                
                override fun onResults(results: android.os.Bundle) {
                    isListening = false
                    timeoutJob?.cancel()
                    
                    val matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    val confidences = results.getFloatArray(SpeechRecognizer.CONFIDENCE_SCORES)
                    
                    if (!matches.isNullOrEmpty()) {
                        val bestMatch = matches[0]
                        val confidence = confidences?.getOrNull(0) ?: 0.5f
                        
                        logger.d("VoiceRecognition", "å•æ¬¡è¯†åˆ«ç»“æœ: $bestMatch (ç½®ä¿¡åº¦: $confidence)")
                        
                        if (!continuation.isCancelled) {
                            continuation.resume(
                                RecognitionResult.Success(
                                    text = bestMatch,
                                    confidence = confidence,
                                    alternatives = matches.drop(1)
                                )
                            )
                        }
                    } else {
                        if (!continuation.isCancelled) {
                            continuation.resume(RecognitionResult.NoMatch)
                        }
                    }
                    
                    cleanup()
                }
                
                override fun onPartialResults(partialResults: android.os.Bundle) {
                    // å•æ¬¡è¯†åˆ«ä¸ä½¿ç”¨éƒ¨åˆ†ç»“æœ
                }
                
                override fun onEvent(eventType: Int, params: android.os.Bundle) {}
                override fun onRmsChanged(rmsdB: Float) {}
                override fun onBufferReceived(buffer: ByteArray) {}
            }
            
            recognizer.setRecognitionListener(recognitionListener)
            
            // è®¾ç½®è¯†åˆ«æ„å›¾
            val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
                putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
                putExtra(RecognizerIntent.EXTRA_LANGUAGE, language)
                putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 1)
                putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS, 1000)
                putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS, 1500)
            }
            
            // å¼€å§‹è¯†åˆ«
            recognizer.startListening(intent)
            
            // è®¾ç½®å–æ¶ˆå›è°ƒ
            continuation.invokeOnCancellation {
                logger.d("VoiceRecognition", "å•æ¬¡è¯†åˆ«è¢«å–æ¶ˆ")
                recognizer.cancel()
                timeoutJob?.cancel()
                cleanup()
            }
        }
    }
    
    /**
     * è¯†åˆ«éŸ³é¢‘æ–‡ä»¶
     */
    suspend fun recognizeAudioFile(
        audioFilePath: String,
        language: String = "zh-CN"
    ): RecognitionResult {
        return suspendCancellableCoroutine { continuation ->
            if (!initialize()) {
                continuation.resume(RecognitionResult.Error(-1, "è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥"))
                return@suspendCancellableCoroutine
            }
            
            val recognizer = speechRecognizer!!
            
            val recognitionListener = object : RecognitionListener {
                override fun onReadyForSpeech(params: android.os.Bundle) {
                    logger.d("VoiceRecognition", "å‡†å¤‡è¯†åˆ«éŸ³é¢‘æ–‡ä»¶")
                }
                
                override fun onBeginningOfSpeech() {
                    logger.d("VoiceRecognition", "å¼€å§‹è¯†åˆ«éŸ³é¢‘æ–‡ä»¶")
                }
                
                override fun onEndOfSpeech() {
                    logger.d("VoiceRecognition", "éŸ³é¢‘æ–‡ä»¶è¯†åˆ«ç»“æŸ")
                }
                
                override fun onError(error: Int) {
                    val errorMessage = when (error) {
                        SpeechRecognizer.ERROR_AUDIO -> "éŸ³é¢‘æ–‡ä»¶é”™è¯¯"
                        SpeechRecognizer.ERROR_CLIENT -> "å®¢æˆ·ç«¯é”™è¯¯"
                        SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> "æƒé™ä¸è¶³"
                        SpeechRecognizer.ERROR_NETWORK -> "ç½‘ç»œé”™è¯¯"
                        SpeechRecognizer.ERROR_NETWORK_TIMEOUT -> "ç½‘ç»œè¶…æ—¶"
                        SpeechRecognizer.ERROR_NO_MATCH -> "æ²¡æœ‰åŒ¹é…çš„ç»“æœ"
                        SpeechRecognizer.ERROR_RECOGNIZER_BUSY -> "è¯†åˆ«å™¨å¿™"
                        SpeechRecognizer.ERROR_SERVER -> "æœåŠ¡å™¨é”™è¯¯"
                        else -> "æœªçŸ¥é”™è¯¯: $error"
                    }
                    
                    logger.e("VoiceRecognition", "éŸ³é¢‘æ–‡ä»¶è¯†åˆ«é”™è¯¯: $errorMessage")
                    
                    if (!continuation.isCancelled) {
                        continuation.resume(RecognitionResult.Error(error, errorMessage))
                    }
                    
                    cleanup()
                }
                
                override fun onResults(results: android.os.Bundle) {
                    val matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    val confidences = results.getFloatArray(SpeechRecognizer.CONFIDENCE_SCORES)
                    
                    if (!matches.isNullOrEmpty()) {
                        val bestMatch = matches[0]
                        val confidence = confidences?.getOrNull(0) ?: 0.5f
                        
                        logger.d("VoiceRecognition", "éŸ³é¢‘æ–‡ä»¶è¯†åˆ«ç»“æœ: $bestMatch (ç½®ä¿¡åº¦: $confidence)")
                        
                        if (!continuation.isCancelled) {
                            continuation.resume(
                                RecognitionResult.Success(
                                    text = bestMatch,
                                    confidence = confidence,
                                    alternatives = matches.drop(1)
                                )
                            )
                        }
                    } else {
                        if (!continuation.isCancelled) {
                            continuation.resume(RecognitionResult.NoMatch)
                        }
                    }
                    
                    cleanup()
                }
                
                override fun onPartialResults(partialResults: android.os.Bundle) {}
                override fun onEvent(eventType: Int, params: android.os.Bundle) {}
                override fun onRmsChanged(rmsdB: Float) {}
                override fun onBufferReceived(buffer: ByteArray) {}
            }
            
            recognizer.setRecognitionListener(recognitionListener)
            
            // è®¾ç½®è¯†åˆ«æ„å›¾ï¼ˆä½¿ç”¨éŸ³é¢‘æ–‡ä»¶ï¼‰
            val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
                putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
                putExtra(RecognizerIntent.EXTRA_LANGUAGE, language)
                putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 5)
                
                // è®¾ç½®éŸ³é¢‘æ–‡ä»¶è·¯å¾„
                putExtra("android.speech.extra.AUDIO_FILE_PATH", audioFilePath)
            }
            
            // å¼€å§‹è¯†åˆ«
            recognizer.startListening(intent)
            
            // è®¾ç½®å–æ¶ˆå›è°ƒ
            continuation.invokeOnCancellation {
                logger.d("VoiceRecognition", "éŸ³é¢‘æ–‡ä»¶è¯†åˆ«è¢«å–æ¶ˆ")
                recognizer.cancel()
                cleanup()
            }
        }
    }
    
    /**
     * è·å–æ”¯æŒçš„è¯­è¨€
     */
    fun getSupportedLanguages(): List<Locale> {
        return try {
            val supported = SpeechRecognizer.getOnDeviceSpeechRecognizer(context)
                ?.getSupportedLanguages()
                ?: emptySet()
            
            supported.map { Locale.forLanguageTag(it) }
                .sortedBy { it.displayName }
        } catch (e: Exception) {
            logger.e("VoiceRecognition", "è·å–æ”¯æŒè¯­è¨€å¤±è´¥", e)
            listOf(Locale.CHINESE, Locale.ENGLISH, Locale("zh", "CN"))
        }
    }
    
    /**
     * æ£€æŸ¥è®¾å¤‡æ˜¯å¦æ”¯æŒè¯­éŸ³è¯†åˆ«
     */
    fun isSpeechRecognitionAvailable(): Boolean {
        return SpeechRecognizer.isRecognitionAvailable(context)
    }
    
    /**
     * è·å–å½“å‰çŠ¶æ€
     */
    fun getStatus(): VoiceRecognitionStatus {
        return VoiceRecognitionStatus(
            isInitialized = speechRecognizer != null,
            isListening = isListening,
            supportedLanguages = getSupportedLanguages()
        )
    }
    
    /**
     * æ·»åŠ ç›‘å¬å™¨
     */
    fun addListener(listener: VoiceRecognitionListener) {
        listeners.add(listener)
    }
    
    /**
     * ç§»é™¤ç›‘å¬å™¨
     */
    fun removeListener(listener: VoiceRecognitionListener) {
        listeners.remove(listener)
    }
    
    /**
     * é€šçŸ¥ç»“æœ
     */
    private fun notifyResult(result: RecognitionResult) {
        listeners.forEach { it.onResult(result) }
    }
    
    /**
     * é€šçŸ¥é”™è¯¯
     */
    private fun notifyError(error: String) {
        listeners.forEach { it.onError(error) }
    }
    
    /**
     * é€šçŸ¥çŠ¶æ€å˜åŒ–
     */
    private fun notifyStatusChanged(isListening: Boolean) {
        listeners.forEach { it.onStatusChanged(isListening) }
    }
    
    /**
     * æ¸…ç†èµ„æº
     */
    private fun cleanup() {
        speechRecognizer?.destroy()
        speechRecognizer = null
        isListening = false
    }
    
    /**
     * é”€æ¯èµ„æº
     */
    fun destroy() {
        stopRecognition()
        cleanup()
    }
}

// æ•°æ®ç±»
data class VoiceRecognitionStatus(
    val isInitialized: Boolean,
    val isListening: Boolean,
    val supportedLanguages: List<Locale>
)